{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03df3ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import neural_manifolds as nm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5bb0a2",
   "metadata": {},
   "source": [
    "# Example: spikes with 2D latent model\n",
    "Here, we construct spikes for $N$ neurons from time-dependent rates $\\nu_i(t)$ that are linear combinations from a latend model with $z(t)$\n",
    "\n",
    "Specifically, we choose \n",
    "$$\n",
    "   z_1(t) = sin(\\pi \\omega t)\\\\\n",
    "   z_2(t) = cos(\\pi \\omega t )\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59679989",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "latent_model = nm.test_data.LatentModel(\"sin_cos\", omega=0.2)\n",
    "\n",
    "t = np.arange(0,100,0.001)\n",
    "latent_state = latent_model(t)\n",
    "print(latent_state.shape)\n",
    "f, axes = plt.subplots(1,2,figsize=((8,3)))\n",
    "axes[0].plot(latent_state[0,:],latent_state[1,:])\n",
    "axes[1].plot(t,latent_state[0,:])\n",
    "axes[1].plot(t,latent_state[1,:])\n",
    "\n",
    "plt.title(\"Latent space\")\n",
    "print(latent_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b05f006",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then, we generate neural firing rates as linear combinations of the latent variables\n",
    "\n",
    "$$\n",
    "  \\nu_i (t) = c_1*z_1(t) + c_2*z_2(t) + offset\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bda286",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from neural_manifolds.test_data import firing_rates\n",
    "# Number of neurons\n",
    "N = 32\n",
    "rates = firing_rates(latent_model, t, N)\n",
    "print(rates.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc86c2e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "To get a bit more realistic, let's generate actual spikes as an inhomogeneous poisson process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f78be",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spikes = nm.test_data.inhomogenous_poisson_spikes(rates, 0.001)\n",
    "\n",
    "ids = np.unique(spikes[:,0])\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(12, 5))\n",
    "for id in ids:\n",
    "    mask = spikes[:,0] == id\n",
    "    spike_times = spikes[mask,1]\n",
    "    ax.plot(spike_times, np.ones_like(spike_times)*id, '|', color='k', markersize=10)\n",
    "\n",
    "ax.set_xlabel('Time [s]')\n",
    "ax.set_ylabel(\"Neuron ID\")\n",
    "ax.set_title(\"Generated Spikes\")\n",
    "ax.set_xlim(0,t.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01942b2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Follow analysis of https://www.nature.com/articles/s41593-019-0555-4\n",
    "\n",
    "Bin spikes in windows of size 30ms, take the square root and then blur with a gaussian kernel of 500ms instead of 50ms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2668fe-e88a-4938-b1b8-5ee42f660803",
   "metadata": {},
   "outputs": [],
   "source": [
    "time, signal = nm.test_data.signals.smooth_spikes(spikes, bin_width = 0.03, std_gaussian = 0.5, sampling_width=0.03, sqrt=True)\n",
    "plt.plot(time, signal.T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a990c40a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "# print(signal.shape)\n",
    "pca.fit(signal.T)\n",
    "# print(pca.explained_variance_ratio_)\n",
    "# print(pca.singular_values_)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), label='on spike data')\n",
    "plt.plot(np.cumsum(pca_orig.explained_variance_ratio_), label='on true rates')\n",
    "plt.xlabel('number of PCs')\n",
    "plt.ylabel('cumulative fraction of variance explained')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e68bcf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Projection on largest two principal components:\n",
    "signal_low_dim = pca.transform(signal.T)[:,:2]\n",
    "f, axes = plt.subplots(1,2,figsize=((8,3)))\n",
    "axes[0].plot(signal_low_dim[:,0],signal_low_dim[:,1])\n",
    "axes[1].plot(signal_low_dim)\n",
    "\n",
    "plt.title(\"Dimension reduction\")\n",
    "plt.plot(signal_low_dim)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf0a73b-b51b-4083-8d12-769f418cb7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "5a93720d1af033579096b7ff56b60a97513f4ea3c4775390f097903a6df54f8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
